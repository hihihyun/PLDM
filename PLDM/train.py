"""
Training script for Underwater Image Enhancement Diffusion Model
"""
import torch
from torch.utils.data import DataLoader
from tqdm import tqdm
import argparse
from pathlib import Path  # ğŸ‘ˆ [ìˆ˜ì • ì™„ë£Œ] ëˆ„ë½ëœ Path import ì¶”ê°€

# ğŸ‘ˆ [ìˆ˜ì • ì™„ë£Œ] import ê²½ë¡œë¥¼ íŒ¨í‚¤ì§€ ë ˆë²¨ë¡œ ëª…í™•í™”
from models.main_model import create_model 
from data.dataset import create_dataloaders
from config import get_config
from utils import AverageMeter, save_checkpoint, set_seed, save_images

class Trainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device(config['device'] if torch.cuda.is_available() else 'cpu')
        print(f"Using device: {self.device}")

        set_seed(config['seed'])

        # Directories
        self.exp_dir = Path(config['exp_dir'])
        self.checkpoint_dir = self.exp_dir / 'checkpoints'
        self.sample_dir = self.exp_dir / 'samples'
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        self.sample_dir.mkdir(parents=True, exist_ok=True)

        # Model, Data, Optimizer
        self.model = create_model(config['model']).to(self.device)
        self.train_loader, self.val_loader = create_dataloaders(config['data'])
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config['training']['lr'])
        self.scaler = torch.cuda.amp.GradScaler(enabled=config.get('use_amp', False))

        self.epoch = 0
        self.global_step = 0
        self.best_val_loss = float('inf') # ğŸ‘ˆ [ì¶”ê°€] ìµœê³ ì˜ ê²€ì¦ ì†ì‹¤ì„ ì¶”ì 

    def train_epoch(self):
        self.model.train()
        meter = AverageMeter()
        pbar = tqdm(self.train_loader, desc=f"Epoch {self.epoch + 1}/{self.config['training']['num_epochs']}")

        for batch in pbar:
            degraded = batch['degraded'].to(self.device)
            enhanced = batch['enhanced'].to(self.device)
            preprocessed = batch.get('preprocessed', None)
            if preprocessed is not None:
                preprocessed = preprocessed.to(self.device)

            self.optimizer.zero_grad()

            with torch.cuda.amp.autocast(enabled=self.config.get('use_amp', False)):
                loss, loss_dict = self.model.training_step(degraded, enhanced, preprocessed)

            self.scaler.scale(loss).backward()
            self.scaler.step(self.optimizer)
            self.scaler.update()

            meter.update(loss.item(), degraded.size(0))
            pbar.set_postfix(loss=f'{meter.avg:.4f}')
            self.global_step += 1

    @torch.no_grad()
    def validate(self):
        self.model.eval()
        val_meter = AverageMeter()
        print("\nConducting validation...")
        
        # ğŸ‘‡ [ìˆ˜ì • ì™„ë£Œ] ì‹¤ì œ ê²€ì¦ ë¡œì§ìœ¼ë¡œ ì™„ì„±
        for batch in tqdm(self.val_loader, desc="Validation"):
            degraded = batch['degraded'].to(self.device)
            enhanced = batch['enhanced'].to(self.device)
            preprocessed = batch.get('preprocessed', None)
            if preprocessed is not None:
                preprocessed = preprocessed.to(self.device)
            
            # ê²€ì¦ì—ì„œëŠ” training_stepì„ ì‚¬ìš©í•˜ì—¬ ì†ì‹¤ë§Œ ê³„ì‚° (ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì—†ìŒ)
            loss, _ = self.model.training_step(degraded, enhanced, preprocessed)
            val_meter.update(loss.item(), degraded.size(0))

        print(f"Validation Loss: {val_meter.avg:.4f}")

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if val_meter.avg < self.best_val_loss:
            self.best_val_loss = val_meter.avg
            print(f"ğŸ‰ New best model found with validation loss: {self.best_val_loss:.4f}")
            save_checkpoint(self.model.state_dict(), self.checkpoint_dir, 'best_model.pth')

        # ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥ (ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ)
        batch = next(iter(self.val_loader))
        degraded = batch['degraded'][:4].to(self.device)
        enhanced_gt = batch['enhanced'][:4].to(self.device)
        pred_enhanced = self.model.sample(degraded)

        # Denormalize to [0, 1] for saving
        degraded = torch.clamp((degraded + 1.0) / 2.0, 0, 1)
        enhanced_gt = torch.clamp((enhanced_gt + 1.0) / 2.0, 0, 1)
        pred_enhanced = torch.clamp((pred_enhanced + 1.0) / 2.0, 0, 1)

        save_path = self.sample_dir / f'epoch_{self.epoch + 1}.png'
        save_images(degraded, enhanced_gt, pred_enhanced, save_path, normalize=False)
        print(f"Saved sample images to {save_path}")

    def train(self):
        for epoch in range(self.config['training']['num_epochs']):
            self.epoch = epoch
            self.train_epoch()

            if (epoch + 1) % self.config['training']['val_freq'] == 0:
                self.validate()

            if (epoch + 1) % self.config['training']['save_freq'] == 0:
                save_checkpoint(self.model.state_dict(), self.checkpoint_dir, f'epoch_{epoch+1}.pth')

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, default='uieb', help='Name of the config to use (e.g., uieb, lsui)')
    args = parser.parse_args()

    config = get_config(config_name=args.config)
    trainer = Trainer(config)
    trainer.train()

if __name__ == "__main__":
    main()