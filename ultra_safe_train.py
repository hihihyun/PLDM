"""
Ultra-safe training script - CPU only, no complex models
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
import os
from tqdm import tqdm
import argparse

class SimplestModel(nn.Module):
    """ê°€ì¥ ë‹¨ìˆœí•œ ëª¨ë¸ - device ë¬¸ì œ ì—†ìŒ"""
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        self.conv3 = nn.Conv2d(32, 16, 3, padding=1)
        self.conv4 = nn.Conv2d(16, 3, 3, padding=1)
        self.relu = nn.ReLU()
        self.tanh = nn.Tanh()
        
    def forward(self, x):
        h = self.relu(self.conv1(x))
        h = self.relu(self.conv2(h))
        h = self.relu(self.conv3(h))
        h = self.tanh(self.conv4(h))
        return h

class SimpleDataset(Dataset):
    """ì™„ì „íˆ ë‹¨ìˆœí•œ ë°ì´í„°ì…‹"""
    def __init__(self, size=100, img_size=64):
        self.size = size
        self.img_size = img_size
        
    def __len__(self):
        return self.size
    
    def __getitem__(self, idx):
        # CPUì—ì„œ ì§ì ‘ ìƒì„±
        degraded = torch.randn(3, self.img_size, self.img_size) * 0.3 + 0.5
        enhanced = degraded * 1.1 + 0.05  # ì•½ê°„ ê°œì„ ëœ ë²„ì „
        
        # [0, 1] ë²”ìœ„ë¡œ í´ë¨í•‘
        degraded = torch.clamp(degraded, 0, 1)
        enhanced = torch.clamp(enhanced, 0, 1)
        
        return degraded, enhanced

def ultra_safe_train():
    """ì™„ì „íˆ ì•ˆì „í•œ í›ˆë ¨"""
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--device', type=str, default='cpu', help='Device (cpu/cuda)')
    parser.add_argument('--epochs', type=int, default=5, help='Epochs')
    parser.add_argument('--batch_size', type=int, default=4, help='Batch size')
    args = parser.parse_args()
    
    print("ğŸ›¡ï¸  ULTRA SAFE UNDERWATER TRAINING")
    print("=" * 50)
    
    device = torch.device(args.device)
    print(f"ğŸ–¥ï¸  Device: {device}")
    
    # 1. ê°€ì¥ ë‹¨ìˆœí•œ ëª¨ë¸
    model = SimplestModel().to(device)
    print(f"âœ… Model created with {sum(p.numel() for p in model.parameters())} parameters")
    
    # 2. ê°€ì¥ ë‹¨ìˆœí•œ ë°ì´í„°
    dataset = SimpleDataset(size=200, img_size=64)
    dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=0)
    print(f"âœ… Dataset created: {len(dataset)} samples")
    
    # 3. ì˜µí‹°ë§ˆì´ì €
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    criterion = nn.MSELoss()
    
    print(f"ğŸ”„ Starting {args.epochs} epochs...")
    
    # 4. í›ˆë ¨ ë£¨í”„
    for epoch in range(args.epochs):
        model.train()
        total_loss = 0
        valid_batches = 0
        
        pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}")
        
        for batch_idx, (degraded, enhanced) in enumerate(pbar):
            try:
                # Deviceë¡œ ì´ë™
                degraded = degraded.to(device)
                enhanced = enhanced.to(device)
                
                # ì •ê·œí™” [-1, 1]
                degraded = degraded * 2.0 - 1.0
                enhanced = enhanced * 2.0 - 1.0
                
                # ìˆœì „íŒŒ
                optimizer.zero_grad()
                pred = model(degraded)
                loss = criterion(pred, enhanced)
                
                # ì—­ì „íŒŒ
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                valid_batches += 1
                
                pbar.set_postfix({'loss': f'{loss.item():.6f}'})
                
                # ì•ˆì „ì„ ìœ„í•´ ë°°ì¹˜ ìˆ˜ ì œí•œ
                if batch_idx >= 100:
                    break
                    
            except Exception as e:
                print(f"âŒ Batch {batch_idx} failed: {e}")
                continue
        
        avg_loss = total_loss / max(valid_batches, 1)
        print(f"Epoch {epoch+1}: Average Loss = {avg_loss:.6f}")
        
        # ê°„ë‹¨í•œ ê²€ì¦
        if epoch % 2 == 0:
            model.eval()
            with torch.no_grad():
                test_degraded, test_enhanced = next(iter(dataloader))
                test_degraded = test_degraded.to(device) * 2.0 - 1.0
                test_enhanced = test_enhanced.to(device) * 2.0 - 1.0
                
                test_pred = model(test_degraded)
                test_loss = criterion(test_pred, test_enhanced)
                print(f"  Validation Loss: {test_loss.item():.6f}")
    
    print("âœ… Ultra safe training completed!")
    
    # ìµœì¢… í…ŒìŠ¤íŠ¸
    print("\nğŸ§ª Final test...")
    model.eval()
    test_input = torch.randn(1, 3, 64, 64).to(device)
    with torch.no_grad():
        test_output = model(test_input)
        print(f"Input shape: {test_input.shape}")
        print(f"Output shape: {test_output.shape}")
        print(f"Output range: [{test_output.min():.3f}, {test_output.max():.3f}]")
    
    # ëª¨ë¸ ì €ì¥
    torch.save(model.state_dict(), 'ultra_safe_model.pth')
    print("ğŸ’¾ Model saved as ultra_safe_model.pth")

if __name__ == "__main__":
    ultra_safe_train()
